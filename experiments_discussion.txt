====================================================
Experiment1
====================================================
    Encoder has low capacity
    Decoder has Dense begining so that intervnetion dont remove half of the image

    Result: It seems, the causal part is removing every information 
            (was a valid solution based on current obj)
            since we just wanted the causal part to be non-discriminative of domain.

            Prolly: putting the ERM constraint on causal part will help here.

====================================================

====================================================
Experiment2
====================================================
    Encoder has low capacity
    Decoder has Dense begining so that intervnetion dont remove half of the image
    Even Discriminator is very low capacity
            This is better choice since then the representation
            will be at max high level, which will make intervnetion
            more meaningful.

    Result: It seems, the causal part is removing every information 
            (was a valid solution based on current obj)
            since we just wanted the causal part to be non-discriminative of domain.

            Yes, now the effect of constant value is even more pronounced
            Atleast they know how to remove everythin.


            Prolly: putting the ERM constraint on causal part will help here.

====================================================


====================================================
Experiment3
====================================================
    Encoder has low capacity
    Decoder has Dense begining so that intervnetion dont remove half of the image
    Even Discriminator is very low capacity
            This is better choice since then the representation
            will be at max high level, which will make intervnetion
            more meaningful.
    Added the Predictor constraint to keep the causal features meaningful

    Result: 
    No difference. The generated image spurious cf has the complete
    image and the generated causal image has none of the actual image,
    but it has some distinction to learn make the classification correct.

    What if we cycle the generated causal counterfactual to be 
    predictive of class.

    Or put the constraint on the generated image.


====================================================

Experiment 4:
Predicotr is now using the images as input, both actual and counterfactual
ones.

The results are more weird. THe training had not converged properly.
And currently we dont see good causal or even spurous generation correctly.


===================================================
Experiment 5:

Lets try very simple case. Given a single digit, can we identify
the 
invariant: digit
spurious/non-invariant : color 

Result:
Same, the causal feature came out to be blank and the non-causal feature 
came out to have all the information. 

===================================================
Experiment 6:

Let try to put dropout in this simple case itself.
So that it tries to diversify its output.


===================================================
Experiment 7:
Need to get adversarial up and running.

